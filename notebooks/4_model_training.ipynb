{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72e83b96",
   "metadata": {},
   "source": [
    "# Model Training Notebook\n",
    "\n",
    "This notebook implements and trains three models for BFRB (Body-Focused Repetitive Behavior) detection:\n",
    "\n",
    "1. **FFT-MLP**: Uses Fast Fourier Transform on IMU data combined with a Multi-Layer Perceptron\n",
    "2. **CNN-BiLSTM**: Uses Convolutional Neural Networks on TOF data with Bidirectional LSTM\n",
    "3. **Late Fusion**: Combines predictions from both models using weighted averaging\n",
    "\n",
    "## Setup and Initialization\n",
    "\n",
    "The following cell imports all necessary libraries and initializes the PyTorch environment with GPU support if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8c184f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import f1_score, confusion_matrix, roc_curve, auc\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"MODEL TRAINING NOTEBOOK\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"Device: {torch.device('cuda' if torch.cuda.is_available() else 'cpu')}\")\n",
    "\n",
    "# Choose device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea66554",
   "metadata": {},
   "source": [
    "## Loading Preprocessed Data\n",
    "\n",
    "This cell loads the preprocessed data that was prepared in the previous notebook (3_preprocessing.ipynb). It includes:\n",
    "- Training, validation, and test sets (X_train, X_val, X_test)\n",
    "- Corresponding labels (y_train, y_val)\n",
    "- The StandardScaler used for normalization\n",
    "\n",
    "The data is then split into feature groups:\n",
    "- **IMU features** (7 features): accelerometer (acc_x, acc_y, acc_z) and rotation quaternion (rot_w, rot_x, rot_y, rot_z)\n",
    "- **TOF features** (320 features): Time-of-Flight sensor data representing a 64Ã—5 grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c831eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LOADING PREPROCESSED DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load preprocessed data\n",
    "with open('../data/X_train_preprocessed.pkl', 'rb') as f:\n",
    "    X_train_scaled = pickle.load(f)\n",
    "\n",
    "with open('../data/X_val_preprocessed.pkl', 'rb') as f:\n",
    "    X_val_scaled = pickle.load(f)\n",
    "\n",
    "with open('../data/X_test_preprocessed.pkl', 'rb') as f:\n",
    "    X_test_scaled = pickle.load(f)\n",
    "\n",
    "with open('../data/y_train_preprocessed.pkl', 'rb') as f:\n",
    "    y_train = pickle.load(f)\n",
    "\n",
    "with open('../data/y_val_preprocessed.pkl', 'rb') as f:\n",
    "    y_val = pickle.load(f)\n",
    "\n",
    "with open('../data/scaler.pkl', 'rb') as f:\n",
    "    scaler = pickle.load(f)\n",
    "\n",
    "print(f\"\\nData loaded successfully:\")\n",
    "print(f\"X_train_scaled: {X_train_scaled.shape}\")\n",
    "print(f\"X_val_scaled: {X_val_scaled.shape}\")\n",
    "print(f\"X_test_scaled: {X_test_scaled.shape}\")\n",
    "print(f\"y_train: {y_train.shape}\")\n",
    "print(f\"y_val: {y_val.shape}\")\n",
    "\n",
    "# Convert to numpy arrays if needed\n",
    "X_train = X_train_scaled.values if isinstance(X_train_scaled, pd.DataFrame) else X_train_scaled\n",
    "X_val = X_val_scaled.values if isinstance(X_val_scaled, pd.DataFrame) else X_val_scaled\n",
    "X_test = X_test_scaled.values if isinstance(X_test_scaled, pd.DataFrame) else X_test_scaled\n",
    "\n",
    "y_train_np = y_train.values if isinstance(y_train, pd.Series) else y_train\n",
    "y_val_np = y_val.values if isinstance(y_val, pd.Series) else y_val\n",
    "\n",
    "print(f\"\\nData types after conversion:\")\n",
    "print(f\"X_train type: {type(X_train)}, shape: {X_train.shape}\")\n",
    "print(f\"y_train type: {type(y_train_np)}, shape: {y_train_np.shape}\")\n",
    "\n",
    "# Feature grouping (for FFT-MLP and CNN-BiLSTM)\n",
    "imu_features = ['acc_x', 'acc_y', 'acc_z', 'rot_w', 'rot_x', 'rot_y', 'rot_z']\n",
    "tof_features = [col for col in X_train_scaled.columns if col.startswith('tof_')]\n",
    "\n",
    "print(f\"\\nFeature groups:\")\n",
    "print(f\"IMU features: {len(imu_features)}\")\n",
    "print(f\"TOF features: {len(tof_features)}\")\n",
    "\n",
    "# Get indices for IMU and TOF features\n",
    "imu_indices = [i for i, col in enumerate(X_train_scaled.columns) if col in imu_features]\n",
    "tof_indices = [i for i, col in enumerate(X_train_scaled.columns) if col in tof_features]\n",
    "\n",
    "print(f\"IMU indices: {len(imu_indices)}\")\n",
    "print(f\"TOF indices: {len(tof_indices)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af45673",
   "metadata": {},
   "source": [
    "## Converting to PyTorch Tensors and Creating DataLoaders\n",
    "\n",
    "This cell performs the following operations:\n",
    "\n",
    "1. **Tensor Conversion**: Converts NumPy arrays to PyTorch tensors (FloatTensor for features, LongTensor for labels)\n",
    "2. **Dataset Creation**: Creates TensorDataset objects that combine features and labels\n",
    "3. **DataLoader Setup**: Creates DataLoader objects with batch_size=128 for efficient mini-batch training\n",
    "   - Training loader shuffles data for better generalization\n",
    "   - Validation and test loaders don't shuffle to maintain consistency\n",
    "\n",
    "DataLoaders handle:\n",
    "- Automatic batching\n",
    "- Multi-threaded data loading\n",
    "- Memory management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680eb7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CONVERTING TO PYTORCH TENSORS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train)\n",
    "X_val_tensor = torch.FloatTensor(X_val)\n",
    "X_test_tensor = torch.FloatTensor(X_test)\n",
    "\n",
    "y_train_tensor = torch.LongTensor(y_train_np)\n",
    "y_val_tensor = torch.LongTensor(y_val_np)\n",
    "\n",
    "print(f\"\\nX_train_tensor: {X_train_tensor.shape}\")\n",
    "print(f\"X_val_tensor: {X_val_tensor.shape}\")\n",
    "print(f\"X_test_tensor: {X_test_tensor.shape}\")\n",
    "print(f\"y_train_tensor: {y_train_tensor.shape}\")\n",
    "print(f\"y_val_tensor: {y_val_tensor.shape}\")\n",
    "\n",
    "# Create DataLoader\n",
    "batch_size = 128\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"\\nDataLoader created successfully:\")\n",
    "print(f\"Training batches: {len(train_loader)}\")\n",
    "print(f\"Validation batches: {len(val_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b84509b",
   "metadata": {},
   "source": [
    "## Model 1: FFT-MLP Architecture\n",
    "\n",
    "This cell defines the **FFT-MLP (Fast Fourier Transform - Multi-Layer Perceptron)** model.\n",
    "\n",
    "### Architecture Details:\n",
    "\n",
    "**Input Processing:**\n",
    "- Extracts IMU data (7 features) from the input tensor\n",
    "- Applies Fast Fourier Transform (FFT) to convert time-domain signals to frequency-domain\n",
    "- Separates FFT result into real and imaginary parts (7Ã—2 = 14 features)\n",
    "\n",
    "**Network Structure:**\n",
    "1. Input Layer: 14 features (FFT real + imaginary components)\n",
    "2. Hidden Layer 1: 128 neurons + ReLU + 30% Dropout\n",
    "3. Hidden Layer 2: 64 neurons + ReLU + 30% Dropout\n",
    "4. Output Layer: 2 classes (Non-Target vs Target behavior)\n",
    "\n",
    "**Key Advantages:**\n",
    "- FFT captures frequency patterns in motion data\n",
    "- Lightweight architecture with few parameters\n",
    "- Fast training and inference\n",
    "- Good for detecting repetitive motion patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6844d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DEFINING FFT-MLP MODEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "class FFT_MLP(nn.Module):\n",
    "    \"\"\"\n",
    "    FFT-MLP model\n",
    "\n",
    "    Steps:\n",
    "    1. Apply FFT to IMU data\n",
    "    2. Extract frequency-domain features\n",
    "    3. Use an MLP for classification\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, imu_dim=7, hidden_dim=128, num_classes=2):\n",
    "        super(FFT_MLP, self).__init__()\n",
    "        \n",
    "        self.imu_dim = imu_dim\n",
    "        \n",
    "        # Number of features after FFT (real + imaginary parts)\n",
    "        fft_features = imu_dim * 2  # 7 * 2 = 14\n",
    "        \n",
    "        # MLP layers\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(fft_features, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(hidden_dim // 2, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (batch_size, 332)\n",
    "        The first 7 columns are IMU data\n",
    "        \"\"\"\n",
    "        # Extract IMU data\n",
    "        imu_data = x[:, :self.imu_dim]  # (batch_size, 7)\n",
    "        \n",
    "        # Apply FFT\n",
    "        fft_result = torch.fft.fft(imu_data, dim=1)  # (batch_size, 7)\n",
    "        \n",
    "        # Separate real and imaginary parts\n",
    "        fft_real = torch.real(fft_result)  # (batch_size, 7)\n",
    "        fft_imag = torch.imag(fft_result)  # (batch_size, 7)\n",
    "        \n",
    "        # Concatenate real and imaginary parts\n",
    "        fft_features = torch.cat([fft_real, fft_imag], dim=1)  # (batch_size, 14)\n",
    "        \n",
    "        # Pass through MLP\n",
    "        output = self.mlp(fft_features)  # (batch_size, 2)\n",
    "        \n",
    "        return output\n",
    "\n",
    "# Initialize model\n",
    "fft_mlp_model = FFT_MLP(imu_dim=7, hidden_dim=128, num_classes=2).to(device)\n",
    "\n",
    "print(f\"\\nFFT-MLP model architecture:\")\n",
    "print(fft_mlp_model)\n",
    "print(f\"\\nParameter count: {sum(p.numel() for p in fft_mlp_model.parameters())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217be76a",
   "metadata": {},
   "source": [
    "## Model 2: CNN-BiLSTM Architecture\n",
    "\n",
    "This cell defines the **CNN-BiLSTM (Convolutional Neural Network - Bidirectional LSTM)** model.\n",
    "\n",
    "### Architecture Details:\n",
    "\n",
    "**Input Processing:**\n",
    "- Extracts TOF (Time-of-Flight) data (320 features)\n",
    "- Reshapes into 2D grid: (64 Ã— 5) representing spatial sensor layout\n",
    "\n",
    "**CNN Layers (Spatial Feature Extraction):**\n",
    "1. Conv2D Layer 1: 1â†’32 channels, 3Ã—3 kernel, padding=1\n",
    "2. ReLU Activation + MaxPool (2Ã—2)\n",
    "3. Conv2D Layer 2: 32â†’64 channels, 3Ã—3 kernel, padding=1\n",
    "4. ReLU Activation + MaxPool (2Ã—2)\n",
    "5. Output: (64, 16, 1) â†’ Flattened to 1024 features\n",
    "\n",
    "**BiLSTM Layers (Temporal Feature Learning):**\n",
    "- 2-layer Bidirectional LSTM\n",
    "- Hidden size: 64 (Ã—2 for bidirectional = 128 total)\n",
    "- Dropout: 30%\n",
    "- Processes spatial features through time\n",
    "\n",
    "**Fully Connected Layers:**\n",
    "1. FC1: 128 â†’ 64 neurons + ReLU + Dropout\n",
    "2. FC2: 64 â†’ 2 classes (output)\n",
    "\n",
    "**Key Advantages:**\n",
    "- CNN extracts spatial patterns from TOF sensor grid\n",
    "- BiLSTM captures temporal dependencies\n",
    "- Handles complex spatial-temporal patterns\n",
    "- Higher capacity for learning detailed features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7611953",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DEFINING CNN-BiLSTM MODEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "class CNN_BiLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    CNN-BiLSTM model\n",
    "\n",
    "    Steps:\n",
    "    1. Use CNN to process TOF data (2D grid: 64Ã—5)\n",
    "    2. Use BiLSTM to learn temporal features\n",
    "    3. Fuse and classify\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, tof_dim=320, hidden_dim=64, num_classes=2):\n",
    "        super(CNN_BiLSTM, self).__init__()\n",
    "        \n",
    "        self.tof_dim = tof_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # CNN layers (process spatial features of TOF)\n",
    "        # Reshape 320 dims into (1, 64, 5) - a 64Ã—5 grid\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Compute CNN output dimension\n",
    "        # Input: (1, 64, 5)\n",
    "        # Conv1: (32, 64, 5)\n",
    "        # Pool: (32, 32, 2)\n",
    "        # Conv2: (64, 32, 2)\n",
    "        # Pool: (64, 16, 1)\n",
    "        cnn_output_dim = 64 * 16 * 1  # = 1024\n",
    "        \n",
    "        # BiLSTM layer\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=cnn_output_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=2,\n",
    "            bidirectional=True,\n",
    "            batch_first=True,\n",
    "            dropout=0.3\n",
    "        )\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (batch_size, 332)\n",
    "        The last 320 columns are TOF data\n",
    "        \"\"\"\n",
    "        # Extract TOF data\n",
    "        tof_data = x[:, -self.tof_dim:]  # (batch_size, 320)\n",
    "        \n",
    "        # Reshape into 2D grid: (batch_size, 1, 64, 5)\n",
    "        batch_size = x.shape[0]\n",
    "        tof_2d = tof_data.view(batch_size, 1, 64, 5)\n",
    "        \n",
    "        # CNN processes spatial features\n",
    "        x = self.conv1(tof_2d)  # (batch_size, 32, 64, 5)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)  # (batch_size, 32, 32, 2)\n",
    "        \n",
    "        x = self.conv2(x)  # (batch_size, 64, 32, 2)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)  # (batch_size, 64, 16, 1)\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(batch_size, -1)  # (batch_size, 1024)\n",
    "        \n",
    "        # LSTM learns temporal features\n",
    "        # LSTM expects (batch_size, seq_len, input_size)\n",
    "        # We only have one time step, so seq_len=1\n",
    "        x = x.unsqueeze(1)  # (batch_size, 1, 1024)\n",
    "        x, (h_n, c_n) = self.lstm(x)  # x: (batch_size, 1, hidden_dim*2)\n",
    "        \n",
    "        # Take the last time step\n",
    "        x = x[:, -1, :]  # (batch_size, hidden_dim*2)\n",
    "        \n",
    "        # Fully connected layer\n",
    "        output = self.fc(x)  # (batch_size, 2)\n",
    "        \n",
    "        return output\n",
    "\n",
    "# Initialize model\n",
    "cnn_bilstm_model = CNN_BiLSTM(tof_dim=320, hidden_dim=64, num_classes=2).to(device)\n",
    "\n",
    "print(f\"\\nCNN-BiLSTM model architecture:\")\n",
    "print(cnn_bilstm_model)\n",
    "print(f\"\\nParameter count: {sum(p.numel() for p in cnn_bilstm_model.parameters())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85e28f0",
   "metadata": {},
   "source": [
    "## Model 3: Late Fusion Architecture\n",
    "\n",
    "This cell defines the **Late Fusion** model that combines predictions from both FFT-MLP and CNN-BiLSTM.\n",
    "\n",
    "### Fusion Strategy:\n",
    "\n",
    "**How It Works:**\n",
    "1. Both FFT-MLP and CNN-BiLSTM make independent predictions (logits)\n",
    "2. Convert logits to probabilities using softmax\n",
    "3. Combine probabilities using weighted averaging:\n",
    "   - FFT-MLP weight: 0.3 (30%)\n",
    "   - CNN-BiLSTM weight: 0.7 (70%)\n",
    "4. Convert fused probabilities back to logits using log transformation\n",
    "\n",
    "**Weight Rationale:**\n",
    "- CNN-BiLSTM gets higher weight (0.7) because it uses more informative TOF data\n",
    "- FFT-MLP provides complementary motion pattern information (0.3)\n",
    "\n",
    "**Important Implementation Detail:**\n",
    "- Returns logits (not probabilities) to work with CrossEntropyLoss\n",
    "- Adds small epsilon (1e-10) to prevent log(0) errors\n",
    "\n",
    "**Key Advantages:**\n",
    "- Leverages strengths of both models\n",
    "- IMU frequency patterns + TOF spatial patterns\n",
    "- Typically achieves better performance than individual models\n",
    "- No additional training needed - uses pre-trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e990a978",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DEFINING LATE FUSION MODEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "class LateFusion(nn.Module):\n",
    "    \"\"\"\n",
    "    Late Fusion model\n",
    "    Returns logits suitable for CrossEntropyLoss\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, fft_mlp_model, cnn_bilstm_model, \n",
    "                 fft_weight=0.3, lstm_weight=0.7):\n",
    "        super(LateFusion, self).__init__()\n",
    "        \n",
    "        self.fft_mlp = fft_mlp_model\n",
    "        self.cnn_bilstm = cnn_bilstm_model\n",
    "        \n",
    "        # Fusion weights\n",
    "        self.fft_weight = fft_weight\n",
    "        self.lstm_weight = lstm_weight\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (batch_size, 332)\n",
    "        Returns: logits (batch_size, 2)\n",
    "        \"\"\"\n",
    "        # Individual model outputs (logits)\n",
    "        fft_logits = self.fft_mlp(x)  # (batch_size, 2)\n",
    "        cnn_logits = self.cnn_bilstm(x)  # (batch_size, 2)\n",
    "        \n",
    "        # Convert logits to probabilities for fusion\n",
    "        fft_proba = torch.softmax(fft_logits, dim=1)  # (batch_size, 2)\n",
    "        cnn_proba = torch.softmax(cnn_logits, dim=1)  # (batch_size, 2)\n",
    "        \n",
    "        # Fuse probabilities\n",
    "        fused_proba = (self.fft_weight * fft_proba + \n",
    "                       self.lstm_weight * cnn_proba)  # (batch_size, 2)\n",
    "        \n",
    "        # Convert probabilities back to logits\n",
    "        fused_logits = torch.log(fused_proba + 1e-10)  # (batch_size, 2)\n",
    "        \n",
    "        return fused_logits  # return logits, not probabilities\n",
    "\n",
    "\n",
    "# Reinitialize fusion model\n",
    "late_fusion_model = LateFusion(\n",
    "    fft_mlp_model, \n",
    "    cnn_bilstm_model,\n",
    "    fft_weight=0.3,\n",
    "    lstm_weight=0.7\n",
    ").to(device)\n",
    "\n",
    "print(\"Late Fusion model initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3722adff",
   "metadata": {},
   "source": [
    "## Training and Validation Functions\n",
    "\n",
    "This cell defines two core functions for the training pipeline:\n",
    "\n",
    "### 1. `train_epoch()` Function\n",
    "Trains the model for one complete pass through the training data.\n",
    "\n",
    "**Process:**\n",
    "- Sets model to training mode (enables dropout/batch norm)\n",
    "- Iterates through mini-batches via DataLoader\n",
    "- For each batch:\n",
    "  1. Moves data to GPU/CPU device\n",
    "  2. Clears gradients (`optimizer.zero_grad()`)\n",
    "  3. Forward pass: computes predictions\n",
    "  4. Calculates loss using CrossEntropyLoss\n",
    "  5. Backward pass: computes gradients\n",
    "  6. Updates weights (`optimizer.step()`)\n",
    "- Tracks predictions and labels for F1 score calculation\n",
    "- Returns average loss and F1 score\n",
    "\n",
    "### 2. `validate_epoch()` Function\n",
    "Evaluates the model on validation data without updating weights.\n",
    "\n",
    "**Process:**\n",
    "- Sets model to evaluation mode (disables dropout/batch norm)\n",
    "- Uses `torch.no_grad()` to disable gradient computation (saves memory)\n",
    "- For each batch:\n",
    "  1. Forward pass only (no backward pass)\n",
    "  2. Calculate loss and predictions\n",
    "  3. Store predictions and probabilities\n",
    "- Computes metrics:\n",
    "  - Average loss\n",
    "  - F1 score\n",
    "  - Confusion matrix\n",
    "- Returns all metrics and predictions for analysis\n",
    "\n",
    "**Progress Tracking:**\n",
    "- Both functions use tqdm progress bars for visual feedback\n",
    "- Display real-time loss values during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4603e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING FUNCTIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device, model_name=\"Model\"):\n",
    "    \"\"\"\n",
    "    Train for one epoch\n",
    "\n",
    "    Params:\n",
    "    - model: PyTorch model\n",
    "    - train_loader: training DataLoader\n",
    "    - criterion: loss function\n",
    "    - optimizer: optimizer\n",
    "    - device: 'cpu' or 'cuda'\n",
    "    - model_name: used for printing\n",
    "\n",
    "    Returns:\n",
    "    - avg_loss: average loss\n",
    "    - avg_f1: average F1 score\n",
    "    \"\"\"\n",
    "    \n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc=f\"Training {model_name}\")\n",
    "    \n",
    "    for batch_idx, (X_batch, y_batch) in enumerate(progress_bar):\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        preds = torch.argmax(y_pred, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(y_batch.cpu().numpy())\n",
    "        \n",
    "        progress_bar.set_postfix({'loss': loss.item()})\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    avg_f1 = f1_score(all_labels, all_preds)\n",
    "    \n",
    "    return avg_loss, avg_f1\n",
    "\n",
    "\n",
    "def validate_epoch(model, val_loader, criterion, device, model_name=\"Model\"):\n",
    "    \"\"\"\n",
    "    Validate for one epoch\n",
    "\n",
    "    Params:\n",
    "    - model: PyTorch model\n",
    "    - val_loader: validation DataLoader\n",
    "    - criterion: loss function\n",
    "    - device: 'cpu' or 'cuda'\n",
    "    - model_name: used for printing\n",
    "\n",
    "    Returns:\n",
    "    - avg_loss: average loss\n",
    "    - avg_f1: average F1\n",
    "    - cm: confusion matrix\n",
    "    - all_preds: all predictions\n",
    "    - all_labels: all labels\n",
    "    \"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_proba = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(val_loader, desc=f\"Validating {model_name}\")\n",
    "        \n",
    "        for X_batch, y_batch in progress_bar:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            \n",
    "            y_pred = model(X_batch)\n",
    "            \n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            proba = torch.softmax(y_pred, dim=1)\n",
    "            preds = torch.argmax(y_pred, dim=1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(y_batch.cpu().numpy())\n",
    "            all_proba.extend(proba.cpu().numpy())\n",
    "    \n",
    "    avg_loss = total_loss / len(val_loader)\n",
    "    avg_f1 = f1_score(all_labels, all_preds)\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    \n",
    "    return avg_loss, avg_f1, cm, all_preds, all_labels\n",
    "\n",
    "print(\"Training and validation functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5696cb76",
   "metadata": {},
   "source": [
    "## Training FFT-MLP Model - Improved Strategy\n",
    "\n",
    "This cell trains the FFT-MLP model using an **improved training strategy** while keeping the original architecture.\n",
    "\n",
    "### Training Configuration:\n",
    "\n",
    "**Hyperparameters:**\n",
    "- **Epochs**: 100 (significantly increased for better convergence)\n",
    "- **Batch Size**: 64 (smaller batches for more stable gradients)\n",
    "- **Optimizer**: SGD with momentum=0.9 (more stable than Adam)\n",
    "- **Learning Rate**: 0.0008\n",
    "- **Weight Decay**: 5e-5 (L2 regularization)\n",
    "\n",
    "**Learning Rate Scheduler:**\n",
    "- Type: ReduceLROnPlateau\n",
    "- Monitors: Validation F1 score\n",
    "- Reduces LR by 50% if no improvement for 5 epochs\n",
    "- Helps escape local minima and fine-tune performance\n",
    "\n",
    "**Early Stopping:**\n",
    "- Patience: 20 epochs\n",
    "- Stops training if validation F1 doesn't improve for 20 consecutive epochs\n",
    "- Prevents overfitting and saves computation time\n",
    "\n",
    "### Training Loop:\n",
    "\n",
    "For each epoch:\n",
    "1. **Training Phase**: Run forward/backward pass on all training batches\n",
    "2. **Validation Phase**: Evaluate on validation set without gradient updates\n",
    "3. **Track Metrics**: Record train/val loss and F1 scores\n",
    "4. **Update Learning Rate**: Scheduler adjusts LR based on validation performance\n",
    "5. **Save Best Model**: Keep model weights with highest validation F1\n",
    "6. **Check Early Stop**: Exit if no improvement for patience epochs\n",
    "\n",
    "**Progress Display:**\n",
    "- Shows detailed stats every 10 epochs\n",
    "- Displays learning rate changes\n",
    "- Highlights new best F1 scores\n",
    "\n",
    "**Model Persistence:**\n",
    "- Saves best model weights to `../data/fft_mlp_best_final.pth`\n",
    "- Loads best weights after training completes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3decffbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Train FFT-MLP\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING FFT-MLP - IMPROVED TRAINING METHOD\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Initialize FFT-MLP\n",
    "fft_mlp_model = FFT_MLP(imu_dim=7, hidden_dim=128, num_classes=2).to(device)\n",
    "\n",
    "print(\"FFT-MLP initialized\")\n",
    "print(\"  Feature extraction: FFT\")\n",
    "print(\"  Classifier: MLP\")\n",
    "\n",
    "# Improved training strategy (keep architecture unchanged)\n",
    "num_epochs = 100\n",
    "learning_rate = 0.0008\n",
    "weight_decay = 5e-5\n",
    "batch_size_train = 64\n",
    "\n",
    "# Recreate DataLoader with smaller batch size\n",
    "train_loader_small = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor),\n",
    "    batch_size=64,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "fft_optimizer = optim.SGD(fft_mlp_model.parameters(),\n",
    "                          lr=learning_rate,\n",
    "                          momentum=0.9,\n",
    "                          weight_decay=weight_decay)\n",
    "\n",
    "# LR scheduler: ReduceLROnPlateau (reduces LR when validation metric plateaus)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    fft_optimizer,\n",
    "    mode='max',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining configuration:\")\n",
    "print(f\"â”œâ”€ Epochs: {num_epochs}\")\n",
    "print(f\"â”œâ”€ Optimizer: SGD with momentum\")\n",
    "print(f\"â”œâ”€ Batch size: {batch_size_train}\")\n",
    "print(f\"â”œâ”€ Learning rate: {learning_rate}\")\n",
    "print(f\"â””â”€ Scheduler: ReduceLROnPlateau\")\n",
    "\n",
    "fft_history = {\n",
    "    'train_loss': [], 'train_f1': [],\n",
    "    'val_loss': [], 'val_f1': [],\n",
    "    'learning_rate': []\n",
    "}\n",
    "best_fft_f1 = 0\n",
    "best_fft_model_state = None\n",
    "no_improve_count = 0\n",
    "patience = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "        print(f\"\\n[Epoch {epoch+1:3d}/{num_epochs}]\")\n",
    "    \n",
    "    # --------- Training ---------\n",
    "    fft_mlp_model.train()\n",
    "    train_total_loss = 0\n",
    "    train_all_preds = []\n",
    "    train_all_labels = []\n",
    "    \n",
    "    show_progress = (epoch + 1) % 10 == 0 or epoch == 0\n",
    "    progress_bar = tqdm(train_loader_small, desc=f\"Epoch {epoch+1:3d} Train\",\n",
    "                       disable=not show_progress)\n",
    "    \n",
    "    for X_batch, y_batch in progress_bar:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        \n",
    "        fft_optimizer.zero_grad()\n",
    "        y_pred = fft_mlp_model(X_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        fft_optimizer.step()\n",
    "        \n",
    "        train_total_loss += loss.item()\n",
    "        preds = torch.argmax(y_pred, dim=1)\n",
    "        train_all_preds.extend(preds.cpu().detach().numpy())\n",
    "        train_all_labels.extend(y_batch.cpu().numpy())\n",
    "    \n",
    "    train_loss = train_total_loss / len(train_loader_small)\n",
    "    train_f1 = f1_score(train_all_labels, train_all_preds)\n",
    "    \n",
    "    # --------- Validation ---------\n",
    "    fft_mlp_model.eval()\n",
    "    val_total_loss = 0\n",
    "    val_all_preds = []\n",
    "    val_all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(val_loader, desc=f\"Epoch {epoch+1:3d} Val\",\n",
    "                           disable=not show_progress)\n",
    "        \n",
    "        for X_batch, y_batch in progress_bar:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            \n",
    "            y_pred = fft_mlp_model(X_batch)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            val_total_loss += loss.item()\n",
    "            \n",
    "            preds = torch.argmax(y_pred, dim=1)\n",
    "            val_all_preds.extend(preds.cpu().numpy())\n",
    "            val_all_labels.extend(y_batch.cpu().numpy())\n",
    "    \n",
    "    val_loss = val_total_loss / len(val_loader)\n",
    "    val_f1 = f1_score(val_all_labels, val_all_preds)\n",
    "    \n",
    "    fft_history['train_loss'].append(train_loss)\n",
    "    fft_history['train_f1'].append(train_f1)\n",
    "    fft_history['val_loss'].append(val_loss)\n",
    "    fft_history['val_f1'].append(val_f1)\n",
    "    fft_history['learning_rate'].append(fft_optimizer.param_groups[0]['lr'])\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "        print(f\"  Train F1: {train_f1:.4f} | Val F1: {val_f1:.4f}\")\n",
    "        print(f\"  LR: {fft_optimizer.param_groups[0]['lr']:.6f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_f1 > best_fft_f1:\n",
    "        best_fft_f1 = val_f1\n",
    "        best_fft_model_state = fft_mlp_model.state_dict()\n",
    "        no_improve_count = 0\n",
    "        if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "            print(f\"  âœ¨ New best F1: {val_f1:.4f}\")\n",
    "    else:\n",
    "        no_improve_count += 1\n",
    "        if no_improve_count >= patience:\n",
    "            print(f\"\\nâš ï¸  Early stopping: no improvement for {patience} epochs\")\n",
    "            break\n",
    "    \n",
    "    # Update LR scheduler based on validation F1\n",
    "    scheduler.step(val_f1)\n",
    "\n",
    "fft_mlp_model.load_state_dict(best_fft_model_state)\n",
    "torch.save(best_fft_model_state, '../data/fft_mlp_best_final.pth')\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(f\" FFT-MLP training complete (architecture unchanged)\")\n",
    "print(f\"â”œâ”€ Best F1: {best_fft_f1:.4f} ({best_fft_f1*100:.2f}%)\")\n",
    "print(f\"â”œâ”€ Architecture: FFT-MLP\")\n",
    "print(f\"â””â”€ Model saved: ../data/fft_mlp_best_final.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9119ec26",
   "metadata": {},
   "source": [
    "## Training CNN-BiLSTM Model\n",
    "\n",
    "This cell trains the CNN-BiLSTM model on TOF sensor data.\n",
    "\n",
    "### Training Configuration:\n",
    "\n",
    "**Hyperparameters:**\n",
    "- **Epochs**: 50\n",
    "- **Learning Rate**: 0.00015 (lower LR for CNN stability)\n",
    "- **Weight Decay**: 1e-4 (L2 regularization)\n",
    "- **Optimizer**: Adam (works well with CNNs and LSTMs)\n",
    "- **Batch Size**: 128 (from DataLoader)\n",
    "\n",
    "**Loss Function:**\n",
    "- CrossEntropyLoss (combines LogSoftmax + NLLLoss)\n",
    "- Suitable for multi-class classification\n",
    "\n",
    "### Training Process:\n",
    "\n",
    "For each of 50 epochs:\n",
    "1. **Training**: Call `train_epoch()` to train on all batches\n",
    "2. **Validation**: Call `validate_epoch()` to evaluate performance\n",
    "3. **Metrics Tracking**: Store train/val loss and F1 scores in history dict\n",
    "4. **Best Model Saving**: \n",
    "   - Track validation F1 score\n",
    "   - Save model state when validation F1 improves\n",
    "   - Update `best_cnn_f1` and `best_cnn_model_state`\n",
    "\n",
    "**Output:**\n",
    "- Displays progress for each epoch\n",
    "- Shows train and validation metrics\n",
    "- Indicates when new best F1 score is achieved\n",
    "\n",
    "**Model Persistence:**\n",
    "- Loads best model weights after training\n",
    "- Saves to `../data/cnn_bilstm_best.pth`\n",
    "- Final F1 score displayed\n",
    "\n",
    "**Why This Model Works:**\n",
    "- CNN effectively processes 2D TOF sensor grid\n",
    "- BiLSTM captures temporal patterns in spatial features\n",
    "- Typically achieves higher F1 than FFT-MLP alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f174db27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TRAINING CNN-BiLSTM MODEL\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING CNN-BiLSTM MODEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Hyperparameters (may need tuning)\n",
    "num_epochs_cnn = 50\n",
    "learning_rate_cnn = 0.00015\n",
    "weight_decay_cnn = 1e-4\n",
    "\n",
    "# Optimizer\n",
    "cnn_optimizer = optim.Adam(cnn_bilstm_model.parameters(), \n",
    "                            lr=learning_rate_cnn, \n",
    "                            weight_decay=weight_decay_cnn)\n",
    "\n",
    "# Training history\n",
    "cnn_history = {'train_loss': [], 'train_f1': [], 'val_loss': [], 'val_f1': []}\n",
    "best_cnn_f1 = 0\n",
    "best_cnn_model_state = None\n",
    "\n",
    "for epoch in range(num_epochs_cnn):\n",
    "    print(f\"\\n[Epoch {epoch+1}/{num_epochs_cnn}]\")\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_f1 = train_epoch(\n",
    "        cnn_bilstm_model, train_loader, criterion, cnn_optimizer, device, \"CNN-BiLSTM\"\n",
    "    )\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_f1, cm, preds, labels = validate_epoch(\n",
    "        cnn_bilstm_model, val_loader, criterion, device, \"CNN-BiLSTM\"\n",
    "    )\n",
    "    \n",
    "    # Record\n",
    "    cnn_history['train_loss'].append(train_loss)\n",
    "    cnn_history['train_f1'].append(train_f1)\n",
    "    cnn_history['val_loss'].append(val_loss)\n",
    "    cnn_history['val_f1'].append(val_f1)\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train F1: {train_f1:.4f}\")\n",
    "    print(f\"Val Loss:   {val_loss:.4f} | Val F1:   {val_f1:.4f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_f1 > best_cnn_f1:\n",
    "        best_cnn_f1 = val_f1\n",
    "        best_cnn_model_state = cnn_bilstm_model.state_dict()\n",
    "        print(f\"âœ¨ New best F1: {val_f1:.4f}\")\n",
    "\n",
    "# Load best weights\n",
    "cnn_bilstm_model.load_state_dict(best_cnn_model_state)\n",
    "\n",
    "# Save model\n",
    "torch.save(best_cnn_model_state, '../data/cnn_bilstm_best.pth')\n",
    "print(f\"\\n CNN-BiLSTM complete! Best F1: {best_cnn_f1:.4f}\")\n",
    "print(\"Model saved to ../data/cnn_bilstm_best.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d10d9d",
   "metadata": {},
   "source": [
    "## Evaluating Late Fusion Model (Inference Only)\n",
    "\n",
    "This cell evaluates the Late Fusion model **without training**. Late Fusion combines pre-trained models using fixed weights.\n",
    "\n",
    "### Why No Training?\n",
    "\n",
    "Late Fusion is an **inference-time** ensemble method:\n",
    "- Uses already-trained FFT-MLP and CNN-BiLSTM models\n",
    "- Combines their predictions using fixed weights (0.3 + 0.7)\n",
    "- No learnable parameters to optimize\n",
    "\n",
    "### Evaluation Process:\n",
    "\n",
    "The `evaluate_late_fusion()` function:\n",
    "1. **Loads Pre-trained Models**: Uses trained FFT-MLP and CNN-BiLSTM\n",
    "2. **Sets to Evaluation Mode**: Disables dropout/batch norm\n",
    "3. **Disables Gradients**: Uses `torch.no_grad()` for efficiency\n",
    "\n",
    "For each validation batch:\n",
    "1. **FFT-MLP Prediction**:\n",
    "   - Get logits from FFT-MLP\n",
    "   - Convert to probabilities via softmax\n",
    "2. **CNN-BiLSTM Prediction**:\n",
    "   - Get logits from CNN-BiLSTM\n",
    "   - Convert to probabilities via softmax\n",
    "3. **Fusion**:\n",
    "   - Weighted average: `0.3 Ã— FFT_proba + 0.7 Ã— CNN_proba`\n",
    "   - Get final prediction via argmax\n",
    "\n",
    "**Metrics Calculated:**\n",
    "- F1 Score\n",
    "- Confusion Matrix\n",
    "- All predictions and probabilities\n",
    "\n",
    "**Detailed Metrics Display:**\n",
    "- Confusion matrix (True/Predicted for both classes)\n",
    "- Accuracy\n",
    "- Precision (how many predicted positives are correct)\n",
    "- Recall (how many actual positives are found)\n",
    "- F1 Score (harmonic mean of precision and recall)\n",
    "\n",
    "**Expected Outcome:**\n",
    "Late Fusion typically achieves the **highest F1 score** by combining complementary strengths of both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6818ee54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# EVALUATE LATE FUSION (inference only)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EVALUATING LATE FUSION MODEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Late Fusion does not require training; it performs weighted averaging of predictions\n",
    "\n",
    "def evaluate_late_fusion(fft_mlp, cnn_bilstm, val_loader, device, \n",
    "                        fft_weight=0.3, lstm_weight=0.7):\n",
    "    \"\"\"\n",
    "    Evaluate Late Fusion (inference only)\n",
    "\n",
    "    Params:\n",
    "    - fft_mlp: trained FFT-MLP model\n",
    "    - cnn_bilstm: trained CNN-BiLSTM model\n",
    "    - val_loader: validation DataLoader\n",
    "    - device: 'cpu' or 'cuda'\n",
    "    - fft_weight: weight for FFT-MLP (default 0.3)\n",
    "    - lstm_weight: weight for CNN-BiLSTM (default 0.7)\n",
    "    \"\"\"\n",
    "    \n",
    "    fft_mlp.eval()\n",
    "    cnn_bilstm.eval()\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_proba_fft = []\n",
    "    all_proba_cnn = []\n",
    "    all_proba_fusion = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(val_loader, desc=\"Evaluating Late Fusion\")\n",
    "        \n",
    "        for X_batch, y_batch in progress_bar:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            \n",
    "            # FFT-MLP prediction\n",
    "            fft_logits = fft_mlp(X_batch)  # (batch_size, 2)\n",
    "            fft_proba = torch.softmax(fft_logits, dim=1)  # (batch_size, 2)\n",
    "            \n",
    "            # CNN-BiLSTM prediction\n",
    "            cnn_logits = cnn_bilstm(X_batch)  # (batch_size, 2)\n",
    "            cnn_proba = torch.softmax(cnn_logits, dim=1)  # (batch_size, 2)\n",
    "            \n",
    "            # Late Fusion: weighted average of probabilities\n",
    "            fusion_proba = (fft_weight * fft_proba + \n",
    "                           lstm_weight * cnn_proba)  # (batch_size, 2)\n",
    "            \n",
    "            fusion_preds = torch.argmax(fusion_proba, dim=1)\n",
    "            \n",
    "            all_preds.extend(fusion_preds.cpu().numpy())\n",
    "            all_labels.extend(y_batch.cpu().numpy())\n",
    "            all_proba_fusion.extend(fusion_proba.cpu().numpy())\n",
    "            all_proba_fft.extend(fft_proba.cpu().numpy())\n",
    "            all_proba_cnn.extend(cnn_proba.cpu().numpy())\n",
    "    \n",
    "    fusion_f1 = f1_score(all_labels, all_preds)\n",
    "    fusion_cm = confusion_matrix(all_labels, all_preds)\n",
    "    \n",
    "    return fusion_f1, fusion_cm, all_preds, all_labels, all_proba_fusion\n",
    "\n",
    "# Evaluate Late Fusion\n",
    "print(\"\\nEvaluating Late Fusion...\")\n",
    "print(\"Weights:\")\n",
    "print(\"â”œâ”€ FFT-MLP: 0.3 (30%)\")\n",
    "print(\"â””â”€ CNN-BiLSTM: 0.7 (70%)\")\n",
    "\n",
    "fusion_f1, fusion_cm, fusion_preds, fusion_labels, fusion_proba = evaluate_late_fusion(\n",
    "    fft_mlp_model,\n",
    "    cnn_bilstm_model,\n",
    "    val_loader,\n",
    "    device,\n",
    "    fft_weight=0.3,\n",
    "    lstm_weight=0.7\n",
    ")\n",
    "\n",
    "print(f\"\\n Late Fusion evaluation complete!\")\n",
    "print(f\"Best F1: {fusion_f1:.4f} ({fusion_f1*100:.2f}%)\")\n",
    "\n",
    "# Print confusion matrix\n",
    "print(f\"\\nConfusion matrix:\")\n",
    "print(f\"  Predicted Non-Target | Predicted Target\")\n",
    "print(f\"True Non-Target: {fusion_cm[0, 0]:>18} | {fusion_cm[0, 1]:>18}\")\n",
    "print(f\"True Target:     {fusion_cm[1, 0]:>18} | {fusion_cm[1, 1]:>18}\")\n",
    "\n",
    "# Additional metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "accuracy = accuracy_score(fusion_labels, fusion_preds)\n",
    "precision = precision_score(fusion_labels, fusion_preds)\n",
    "recall = recall_score(fusion_labels, fusion_preds)\n",
    "\n",
    "print(f\"\\nDetailed metrics:\")\n",
    "print(f\"â”œâ”€ Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"â”œâ”€ Precision: {precision:.4f} ({precision*100:.2f}%)\")\n",
    "print(f\"â”œâ”€ Recall: {recall:.4f} ({recall*100:.2f}%)\")\n",
    "print(f\"â””â”€ F1 Score: {fusion_f1:.4f} ({fusion_f1*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e6acb0",
   "metadata": {},
   "source": [
    "## Results Visualization and Summary\n",
    "\n",
    "This cell generates comprehensive visualizations and summary statistics for all three models.\n",
    "\n",
    "### Visualization Components:\n",
    "\n",
    "**1. Results Data Collection:**\n",
    "- Reads F1 scores from training (FFT-MLP, CNN-BiLSTM, Late Fusion)\n",
    "- Automatically calculates parameter counts from saved models\n",
    "- Computes efficiency metrics (F1 per parameter)\n",
    "\n",
    "**2. Six-Panel Visualization:**\n",
    "\n",
    "**Panel 1 - F1 Score Comparison:**\n",
    "- Bar chart comparing F1 scores across all models\n",
    "- Shows exact F1 values and percentages\n",
    "- Y-axis range: 0.75-1.0 for clarity\n",
    "\n",
    "**Panel 2 - F1 Score Ranking:**\n",
    "- Same data with ranking medals (ðŸ¥‡ðŸ¥ˆðŸ¥‰)\n",
    "- Highlights performance order\n",
    "\n",
    "**Panel 3 - Parameter Count:**\n",
    "- Log-scale bar chart of model parameters\n",
    "- Shows model complexity\n",
    "- Labels in thousands (K)\n",
    "\n",
    "**Panel 4 - Model Efficiency:**\n",
    "- F1 score divided by parameter count\n",
    "- Higher = better performance per parameter\n",
    "- Identifies most efficient architecture\n",
    "\n",
    "**Panel 5 - Detailed Data Table:**\n",
    "- Tabular view of all metrics\n",
    "- Model name, F1 score, percentage, parameters\n",
    "- Color-coded headers and alternating row colors\n",
    "\n",
    "**Panel 6 - Performance Level:**\n",
    "- Horizontal bar chart with quality ratings\n",
    "- Color-coded performance tiers:\n",
    "  - Excellent (â‰¥0.92): Green\n",
    "  - Very Good (â‰¥0.90): Blue\n",
    "  - Good (â‰¥0.85): Orange\n",
    "  - Passing (<0.85): Red\n",
    "\n",
    "**3. Summary Statistics:**\n",
    "- Prints formatted table to console\n",
    "- Shows average, max, and min F1 scores\n",
    "- Identifies best and worst performers\n",
    "\n",
    "**4. Data Export:**\n",
    "- Saves visualization as high-quality PNG (300 DPI)\n",
    "- Exports results to CSV for further analysis\n",
    "- Includes efficiency and performance level columns\n",
    "\n",
    "**Output Files:**\n",
    "- `../data/model_visualization_final.png` - Complete visualization\n",
    "- `../data/results_summary.csv` - Machine-readable results table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ca1e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Results Visualization and Summary\n",
    "# ============================================================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "print(\"\\nReading training results...\")\n",
    "\n",
    "# Example: directly using results computed or loaded from training\n",
    "results = {\n",
    "    'FFT-MLP': {\n",
    "        'f1': 0.8337,\n",
    "        'model_path': '../data/fft_mlp_best_final.pth',\n",
    "        'color': '#FF6B6B'\n",
    "    },\n",
    "    'CNN-BiLSTM': {\n",
    "        'f1': 0.9141,\n",
    "        'model_path': '../data/cnn_bilstm_best.pth',\n",
    "        'color': '#4ECDC4'\n",
    "    },\n",
    "    'Late Fusion': {\n",
    "        'f1': 0.9193,\n",
    "        'model_path': None,\n",
    "        'color': '#45B7D1'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Automatically compute parameter counts\n",
    "print(\"Reading model parameter counts...\")\n",
    "for model_name, model_info in results.items():\n",
    "    if model_info['model_path'] and os.path.exists(model_info['model_path']):\n",
    "        state_dict = torch.load(model_info['model_path'])\n",
    "        param_count = sum(p.numel() for p in state_dict.values())\n",
    "        model_info['params'] = param_count\n",
    "        print(f\"  {model_name}: {param_count:,} parameters\")\n",
    "    else:\n",
    "        if model_name == 'Late Fusion':\n",
    "            params_fft = sum(p.numel() for p in torch.load(results['FFT-MLP']['model_path']).values())\n",
    "            params_cnn = sum(p.numel() for p in torch.load(results['CNN-BiLSTM']['model_path']).values())\n",
    "            model_info['params'] = params_fft + params_cnn\n",
    "            print(f\"  {model_name}: {model_info['params']:,} parameters (fusion)\")\n",
    "\n",
    "print(\"\\nGenerating visualizations...\")\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (16, 12)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "fig = plt.figure(figsize=(18, 12))\n",
    "\n",
    "models = list(results.keys())\n",
    "f1_scores = [results[m]['f1'] for m in models]\n",
    "params = [results[m]['params']/1000 for m in models]\n",
    "colors = [results[m]['color'] for m in models]\n",
    "\n",
    "# Panel 1: F1 score comparison\n",
    "ax1 = plt.subplot(2, 3, 1)\n",
    "bars = ax1.bar(models, f1_scores, color=colors, alpha=0.8, edgecolor='black', linewidth=2)\n",
    "ax1.set_ylabel('F1 Score', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('F1 Scores of the Three Models', fontsize=13, fontweight='bold')\n",
    "ax1.set_ylim([0.75, 1.0])\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for bar, score in zip(bars, f1_scores):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{score:.4f}\\n({score*100:.2f}%)',\n",
    "             ha='center', va='bottom', fontweight='bold', fontsize=11)\n",
    "\n",
    "# Panel 2: Ranking\n",
    "ax2 = plt.subplot(2, 3, 2)\n",
    "bars = ax2.bar(models, f1_scores, color=colors, alpha=0.8, edgecolor='black', linewidth=2)\n",
    "ax2.set_ylabel('F1 Score', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('F1 Score Ranking', fontsize=13, fontweight='bold')\n",
    "ax2.set_ylim([0.75, 1.0])\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for i, (bar, score) in enumerate(zip(bars, f1_scores), 1):\n",
    "    height = bar.get_height()\n",
    "    rank = 'ðŸ¥‡' if i == 3 else 'ðŸ¥ˆ' if i == 2 else 'ðŸ¥‰'\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "             f'{rank} #{i}',\n",
    "             ha='center', va='bottom', fontweight='bold', fontsize=11)\n",
    "\n",
    "# Panel 3: Parameter counts\n",
    "ax3 = plt.subplot(2, 3, 3)\n",
    "bars = ax3.bar(models, params, color=colors, alpha=0.8, edgecolor='black', linewidth=2)\n",
    "ax3.set_ylabel('Parameters (K)', fontsize=12, fontweight='bold')\n",
    "ax3.set_title('Model Parameter Counts', fontsize=13, fontweight='bold')\n",
    "ax3.set_yscale('log')\n",
    "ax3.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for bar, param in zip(bars, params):\n",
    "    height = bar.get_height()\n",
    "    if param > 100:\n",
    "        label = f'{param:.0f}K'\n",
    "    else:\n",
    "        label = f'{param:.1f}K'\n",
    "    ax3.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             label,\n",
    "             ha='center', va='bottom', fontweight='bold', fontsize=11)\n",
    "\n",
    "# Panel 4: Efficiency (F1 / params)\n",
    "ax4 = plt.subplot(2, 3, 4)\n",
    "efficiency = [f1/p for f1, p in zip(f1_scores, params)]\n",
    "\n",
    "bars = ax4.bar(models, efficiency, color=colors, alpha=0.8, edgecolor='black', linewidth=2)\n",
    "ax4.set_ylabel('F1 / Parameters (efficiency)', fontsize=12, fontweight='bold')\n",
    "ax4.set_title('Model Efficiency (F1 / params)', fontsize=13, fontweight='bold')\n",
    "ax4.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for bar, eff in zip(bars, efficiency):\n",
    "    height = bar.get_height()\n",
    "    ax4.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{eff:.5f}',\n",
    "             ha='center', va='bottom', fontweight='bold', fontsize=10)\n",
    "\n",
    "# Panel 5: Data table\n",
    "ax5 = plt.subplot(2, 3, 5)\n",
    "ax5.axis('tight')\n",
    "ax5.axis('off')\n",
    "\n",
    "table_data = []\n",
    "for model_name, model_info in results.items():\n",
    "    table_data.append([\n",
    "        model_name,\n",
    "        f\"{model_info['f1']:.4f}\",\n",
    "        f\"{model_info['f1']*100:.2f}%\",\n",
    "        f\"{model_info['params']:,}\"\n",
    "    ])\n",
    "\n",
    "table = ax5.table(cellText=table_data,\n",
    "                 colLabels=['Model', 'F1 Score', 'F1 %', 'Parameters'],\n",
    "                 cellLoc='center',\n",
    "                 loc='center',\n",
    "                 colWidths=[0.25, 0.25, 0.25, 0.25])\n",
    "\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(10)\n",
    "table.scale(1, 2)\n",
    "\n",
    "for i in range(4):\n",
    "    table[(0, i)].set_facecolor('#4ECDC4')\n",
    "    table[(0, i)].set_text_props(weight='bold', color='white')\n",
    "\n",
    "for i in range(1, len(table_data) + 1):\n",
    "    for j in range(4):\n",
    "        if i % 2 == 0:\n",
    "            table[(i, j)].set_facecolor('#f0f0f0')\n",
    "        else:\n",
    "            table[(i, j)].set_facecolor('white')\n",
    "\n",
    "ax5.set_title('Detailed Data Table', fontsize=13, fontweight='bold', pad=20)\n",
    "\n",
    "# Panel 6: Performance levels\n",
    "ax6 = plt.subplot(2, 3, 6)\n",
    "\n",
    "def get_performance_level(f1):\n",
    "    if f1 >= 0.92:\n",
    "        return 'Excellent', '#2ECC71'\n",
    "    elif f1 >= 0.90:\n",
    "        return 'Very Good', '#3498DB'\n",
    "    elif f1 >= 0.85:\n",
    "        return 'Good', '#F39C12'\n",
    "    else:\n",
    "        return 'Passing', '#E74C3C'\n",
    "\n",
    "levels = [get_performance_level(f1)[0] for f1 in f1_scores]\n",
    "level_colors = [get_performance_level(f1)[1] for f1 in f1_scores]\n",
    "\n",
    "bars = ax6.barh(models, f1_scores, color=level_colors, alpha=0.8, edgecolor='black', linewidth=2)\n",
    "ax6.set_xlabel('F1 Score', fontsize=12, fontweight='bold')\n",
    "ax6.set_title('Performance Level', fontsize=13, fontweight='bold')\n",
    "ax6.set_xlim([0.75, 1.0])\n",
    "ax6.grid(axis='x', alpha=0.3)\n",
    "\n",
    "for bar, score, level in zip(bars, f1_scores, levels):\n",
    "    width = bar.get_width()\n",
    "    ax6.text(width - 0.02, bar.get_y() + bar.get_height()/2.,\n",
    "             f'{score:.4f} ({level})',\n",
    "             ha='right', va='center', fontweight='bold', fontsize=11, color='white')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/model_visualization_final.png', dpi=300, bbox_inches='tight')\n",
    "print(' Visualization saved to: ../data/model_visualization_final.png')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" RESULTS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nFinal results for the three models:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Model':<15} | {'F1 Score':<15} | {'Parameters':<15} | {'Performance':<10}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for model_name in models:\n",
    "    f1 = results[model_name]['f1']\n",
    "    params_count = results[model_name]['params']\n",
    "    level, _ = get_performance_level(f1)\n",
    "    \n",
    "    print(f\"{model_name:<15} | {f1:.4f} ({f1*100:5.2f}%) | {params_count:>14,} | {level:<10}\")\n",
    "\n",
    "print(\"-\" * 80)\n",
    "\n",
    "avg_f1 = sum(f1_scores) / len(f1_scores)\n",
    "print(f\"\\nAverage F1: {avg_f1:.4f} ({avg_f1*100:.2f}%)\")\n",
    "print(f\"Best F1: {max(f1_scores):.4f} ({max(f1_scores)*100:.2f}%) - {models[f1_scores.index(max(f1_scores))]}\")\n",
    "print(f\"Worst F1: {min(f1_scores):.4f} ({min(f1_scores)*100:.2f}%) - {models[f1_scores.index(min(f1_scores))]}\")\n",
    "\n",
    "print(f\"\\nAll models have been trained and evaluated.\")\n",
    "print(f\"Visualization generated: ../data/model_visualization_final.png\")\n",
    "\n",
    "# Save results to CSV\n",
    "print(f\"\\nSaving results to CSV...\")\n",
    "\n",
    "results_data = {\n",
    "    'Model': models,\n",
    "    'F1 Score': f1_scores,\n",
    "    'F1 %': [f'{f1*100:.2f}%' for f1 in f1_scores],\n",
    "    'Parameters': [results[m]['params'] for m in models],\n",
    "    'Efficiency': [f1/p for f1, p in zip(f1_scores, [results[m]['params'] for m in models])],\n",
    "    'Performance': [get_performance_level(f1)[0] for f1 in f1_scores]\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(results_data)\n",
    "results_df.to_csv('../data/results_summary.csv', index=False, encoding='utf-8-sig')\n",
    "print(' Results saved to: ../data/results_summary.csv')\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
